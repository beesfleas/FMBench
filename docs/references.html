<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>References - FMBench</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="sidebar">
        <h2>FMBench</h2>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="slides.html">Slides</a></li>
                <li><a href="report.html">Report</a></li>
                <li><a href="data_appendix.html">Data Appendix</a></li>
                <li><a href="supplementary.html">Supplementary</a></li>
                <li><a href="tutorial.html">Tutorial</a></li>
                <li><a href="references.html" class="active">References</a></li>
            </ul>
        </nav>
    </div>

    <div class="main-content">
        <h1>References</h1>

        <section class="section">
            <h2 id="datasets">Datasets</h2>

            <h3 id="ref-arc">AI2 Abstraction and Reasoning Corpus (ARC)</h3>
            <p>Clark, P., Cowhey, I., Etzioni, O., Khot, T., Sabharwal, A., Schoenick, C., & Tafjord, O. (2018).
                Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge.
                <em>arXiv preprint arXiv:1803.05457</em>.
            </p>
            <p><a href="https://allenai.org/data/arc" target="_blank">https://allenai.org/data/arc</a></p>

            <h3 id="ref-mmlu">Massive Multitask Language Understanding (MMLU)</h3>
            <p>Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt, J. (2021).
                Measuring Massive Multitask Language Understanding.
                <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>.
            </p>
            <p><a href="https://github.com/hendrycks/test" target="_blank">https://github.com/hendrycks/test</a></p>

            <h3 id="ref-agnews">AG News Classification Dataset</h3>
            <p>Zhang, X., Zhao, J., & LeCun, Y. (2015).
                Character-level Convolutional Networks for Text Classification.
                <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 28.
            </p>
            <p><a href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html"
                    target="_blank">http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html</a></p>

            <h3 id="ref-imdb">IMDB Movie Reviews Dataset</h3>
            <p>Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C. (2011).
                Learning Word Vectors for Sentiment Analysis.
                <em>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL)</em>,
                142-150.
            </p>
            <p><a href="https://ai.stanford.edu/~amaas/data/sentiment/"
                    target="_blank">https://ai.stanford.edu/~amaas/data/sentiment/</a></p>

            <h3 id="ref-wikiann">WikiANN Named Entity Recognition</h3>
            <p>Pan, X., Zhang, B., May, J., Nothman, J., Knight, K., & Ji, H. (2017).
                Cross-lingual Name Tagging and Linking for 282 Languages.
                <em>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)</em>,
                1946-1958.
            </p>
            <p><a href="https://github.com/afshinrahimi/mmner" target="_blank">https://github.com/afshinrahimi/mmner</a>
            </p>

            <h3 id="ref-cnndm">CNN/DailyMail Summarization Dataset</h3>
            <p>Hermann, K. M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M., & Blunsom, P. (2015).
                Teaching Machines to Read and Comprehend.
                <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 28.
            </p>
            <p><a href="https://github.com/abisee/cnn-dailymail"
                    target="_blank">https://github.com/abisee/cnn-dailymail</a></p>

            <h3 id="ref-wmt16">WMT16 Translation Dataset</h3>
            <p>Bojar, O., et al. (2016).
                Findings of the 2016 Conference on Machine Translation.
                <em>Proceedings of the First Conference on Machine Translation (WMT)</em>, 131-198.
            </p>
            <p><a href="https://www.statmt.org/wmt16/" target="_blank">https://www.statmt.org/wmt16/</a></p>

            <h3 id="ref-countbench">CountBenchQA</h3>
            <p>Paiss, R., Ephrat, A., Toshev, A., Naor, S., Mosseri, I., Irani, M., & Freeman, W. T. (2023).
                Teaching CLIP to Count to Ten.
                <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>.
            </p>
            <p><a href="https://github.com/teaching-clip-to-count/teaching-clip-to-count"
                    target="_blank">https://github.com/teaching-clip-to-count/teaching-clip-to-count</a></p>

            <h3 id="ref-docvqa">DocVQA</h3>
            <p>Mathew, M., Karatzas, D., & Jawahar, C. V. (2021).
                DocVQA: A Dataset for VQA on Document Images.
                <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>,
                2200-2209.
            </p>
            <p><a href="https://www.docvqa.org/" target="_blank">https://www.docvqa.org/</a></p>

            <h3 id="ref-gtsrb">German Traffic Sign Recognition Benchmark (GTSRB)</h3>
            <p>Stallkamp, J., Schlipsing, M., Salmen, J., & Igel, C. (2012).
                Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition.
                <em>Neural Networks</em>, 32, 323-332.
            </p>
            <p><a href="https://benchmark.ini.rub.de/" target="_blank">https://benchmark.ini.rub.de/</a></p>

            <h3 id="ref-hagrid">HaGRID - HAnd Gesture Recognition Image Dataset</h3>
            <p>Kapitanov, A., Makhlyarchuk, A., & Kvanchiani, K. (2022).
                HaGRID - HAnd Gesture Recognition Image Dataset.
                <em>arXiv preprint arXiv:2206.08219</em>.
            </p>
            <p><a href="https://github.com/hukenovs/hagrid" target="_blank">https://github.com/hukenovs/hagrid</a></p>

            <h3 id="ref-vqav2">Visual Question Answering v2.0 (VQAv2)</h3>
            <p>Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., & Parikh, D. (2017).
                Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering.
                <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                6904-6913.
            </p>
            <p><a href="https://visualqa.org/" target="_blank">https://visualqa.org/</a></p>

            <h3 id="ref-ett">Electricity Transformer Temperature (ETT) Dataset</h3>
            <p>Zhou, H., Zhang, S., Peng, J., Zhang, S., Li, J., Xiong, H., & Zhang, W. (2021).
                Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting.
                <em>Proceedings of the AAAI Conference on Artificial Intelligence</em>, 35(12), 11106-11115.
            </p>
            <p><a href="https://github.com/zhouhaoyi/ETDataset"
                    target="_blank">https://github.com/zhouhaoyi/ETDataset</a></p>

            <h3 id="ref-gifteval">GiftEval</h3>
            <p>Liu, Y., et al. (2024).
                GiftEval: A Benchmark for General Time Series Forecasting Model Evaluation.
                <em>arXiv preprint arXiv:2406.xxxxx</em>.
            </p>
            <p><a href="https://github.com/SalesforceAIResearch/GiftEval"
                    target="_blank">https://github.com/SalesforceAIResearch/GiftEval</a></p>

            <h3 id="ref-m3">M3 Competition Dataset</h3>
            <p>Makridakis, S., & Hibon, M. (2000).
                The M3-Competition: results, conclusions and implications.
                <em>International Journal of Forecasting</em>, 16(4), 451-476.
            </p>
            <p><a href="https://forecasters.org/resources/time-series-data/m3-competition/"
                    target="_blank">https://forecasters.org/resources/time-series-data/m3-competition/</a></p>

            <h3 id="ref-c4">C4 (Colossal Clean Crawled Corpus)</h3>
            <p>Raffel, C., et al. (2020).
                Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.
                <em>Journal of Machine Learning Research</em>, 21(140), 1-67.
            </p>
            <p><a href="https://www.tensorflow.org/datasets/catalog/c4"
                    target="_blank">https://www.tensorflow.org/datasets/catalog/c4</a></p>

            <h3 id="ref-wikitext">WikiText</h3>
            <p>Merity, S., Xiong, C., Bradbury, J., & Socher, R. (2017).
                Pointer Sentinel Mixture Models.
                <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>.
            </p>
            <p><a href="https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/"
                    target="_blank">https://blog.salesforceairesearch.com/the-wikitext-long-term-dependency-language-modeling-dataset/</a>
            </p>
        </section>

        <section class="section">
            <h2 id="libraries">Libraries and Frameworks</h2>

            <h3 id="ref-pytorch">PyTorch</h3>
            <p>Paszke, A., et al. (2019).
                PyTorch: An Imperative Style, High-Performance Deep Learning Library.
                <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 32.
            </p>
            <p><a href="https://pytorch.org/" target="_blank">https://pytorch.org/</a></p>

            <h3 id="ref-transformers">Hugging Face Transformers</h3>
            <p>Wolf, T., et al. (2020).
                Transformers: State-of-the-Art Natural Language Processing.
                <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP):
                    System Demonstrations</em>, 38-45.
            </p>
            <p><a href="https://huggingface.co/transformers/" target="_blank">https://huggingface.co/transformers/</a>
            </p>

            <h3 id="ref-hydra">Hydra</h3>
            <p>Yadan, O. (2019).
                Hydra - A framework for elegantly configuring complex applications.
                <em>GitHub repository</em>.
            </p>
            <p><a href="https://hydra.cc/" target="_blank">https://hydra.cc/</a></p>

            <h3 id="ref-sacrebleu">SacreBLEU</h3>
            <p>Post, M. (2018).
                A Call for Clarity in Reporting BLEU Scores.
                <em>Proceedings of the Third Conference on Machine Translation (WMT)</em>, 186-191.
            </p>
            <p><a href="https://github.com/mjpost/sacrebleu" target="_blank">https://github.com/mjpost/sacrebleu</a></p>

            <h3 id="ref-bertscore">BERTScore</h3>
            <p>Zhang, T., Kishore, V., Wu, F., Weinberger, K. Q., & Artzi, Y. (2020).
                BERTScore: Evaluating Text Generation with BERT.
                <em>Proceedings of the International Conference on Learning Representations (ICLR)</em>.
            </p>
            <p><a href="https://github.com/Tiiiger/bert_score" target="_blank">https://github.com/Tiiiger/bert_score</a>
            </p>

            <h3 id="ref-comet">COMET</h3>
            <p>Rei, R., Stewart, C., Farinha, A. C., & Lavie, A. (2020).
                COMET: A Neural Framework for MT Evaluation.
                <em>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em>,
                2685-2702.
            </p>
            <p><a href="https://github.com/Unbabel/COMET" target="_blank">https://github.com/Unbabel/COMET</a></p>

            <h3 id="ref-accelerate">Accelerate</h3>
            <p>Hugging Face. Accelerate: Training and inference at scale made simple, efficient and adaptable.
                <em>GitHub repository</em>.
            </p>
            <p><a href="https://github.com/huggingface/accelerate"
                    target="_blank">https://github.com/huggingface/accelerate</a></p>

            <h3 id="ref-omegaconf">OmegaConf</h3>
            <p>OmegaConf Contributors. OmegaConf: A hierarchical configuration system.
                <em>GitHub repository</em>.
            </p>
            <p><a href="https://github.com/omry/omegaconf" target="_blank">https://github.com/omry/omegaconf</a></p>

            <h3 id="ref-datasets">Hugging Face Datasets</h3>
            <p>Lhoest, Q., et al. (2021).
                Datasets: A Community Library for Natural Language Processing.
                <em>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System
                    Demonstrations</em>, 175-184.
            </p>
            <p><a href="https://github.com/huggingface/datasets"
                    target="_blank">https://github.com/huggingface/datasets</a></p>

            <h3 id="ref-pillow">Pillow (PIL Fork)</h3>
            <p>Clark, A., et al. Pillow: Python Imaging Library (Fork).
                <em>GitHub repository</em>.
            </p>
            <p><a href="https://github.com/python-pillow/Pillow"
                    target="_blank">https://github.com/python-pillow/Pillow</a></p>

            <h3 id="ref-pandas">Pandas</h3>
            <p>McKinney, W. (2010).
                Data Structures for Statistical Computing in Python.
                <em>Proceedings of the 9th Python in Science Conference</em>, 56-61.
            </p>
            <p><a href="https://pandas.pydata.org/" target="_blank">https://pandas.pydata.org/</a></p>

            <h3 id="ref-nltk">NLTK (Natural Language Toolkit)</h3>
            <p>Bird, S., Klein, E., & Loper, E. (2009).
                Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit.
                <em>O'Reilly Media Inc</em>.
            </p>
            <p><a href="https://www.nltk.org/" target="_blank">https://www.nltk.org/</a></p>

            <h3 id="ref-nvml">nvidia-ml-py</h3>
            <p>NVIDIA. Python Bindings for the NVIDIA Management Library.
                <em>GitHub repository</em>.
            </p>
            <p><a href="https://github.com/gpuopenanalytics/pynvml"
                    target="_blank">https://github.com/gpuopenanalytics/pynvml</a></p>

            <h3 id="ref-psutil">psutil</h3>
            <p>Rodola, G. (2009).
                psutil: Cross-platform lib for process and system monitoring in Python.
                <em>GitHub repository</em>.
            </p>
            <p><a href="https://github.com/giampaolo/psutil" target="_blank">https://github.com/giampaolo/psutil</a></p>

            <h3 id="ref-compressed-tensors">compressed_tensors (vLLM)</h3>
            <p>Kwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu, C. H., Gonzalez, J. E., Zhang, H., & Stoica, I.
                (2023).
                Efficient Memory Management for Large Language Model Serving with PagedAttention.
                <em>Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</em>.
            </p>
            <p><a href="https://github.com/vllm-project/vllm" target="_blank">https://github.com/vllm-project/vllm</a>
            </p>

            <h3 id="ref-seaborn">Seaborn</h3>
            <p>Waskom, M. L. (2021).
                seaborn: statistical data visualization.
                <em>Journal of Open Source Software</em>, 6(60), 3021.
            </p>
            <p><a href="https://doi.org/10.21105/joss.03021" target="_blank">https://doi.org/10.21105/joss.03021</a></p>

            <h3 id="ref-hf-hub">huggingface_hub</h3>
            <p>Hugging Face. huggingface_hub: Client library for the Hugging Face Hub.
                <em>GitHub repository</em>.
            </p>
            <p><a href="https://github.com/huggingface/huggingface_hub"
                    target="_blank">https://github.com/huggingface/huggingface_hub</a></p>
        </section>

        <footer>
            <p>&copy; 2025 FMBench Project</p>
        </footer>
    </div>
</body>

</html>