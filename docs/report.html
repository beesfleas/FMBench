<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <!DOCTYPE html>
    <html lang="en">

    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Report - FMBench</title>
        <link rel="stylesheet" href="style.css">
    </head>

<body>
    <div class="sidebar">
        <h2>FMBench</h2>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="slides.html">Slides</a></li>
                <li><a href="report.html" class="active">Report</a></li>
                <li><a href="data_appendix.html">Data Appendix</a></li>
                <li><a href="supplementary.html">Supplementary</a></li>
                <li><a href="tutorial.html">Tutorial</a></li>
                <li><a href="references.html">References</a></li>
            </ul>
        </nav>
    </div>

    <div class="main-content">
        <h1>Project Report</h1>

        <div class="toc">
            <h3>Table of Contents</h3>
            <ul>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#related-work">Related Work</a></li>
                <li><a href="#technical-approach">Technical Approach</a></li>
                <li><a href="#evaluation">Evaluation and Results</a></li>
                <li><a href="#discussions">Discussions and Conclusions</a></li>
                <li><a href="#references">References</a></li>
            </ul>
        </div>

        <hr>

        <section id="introduction" class="section">
            <h2>Introduction</h2>
            <p>[Content for Introduction goes here...]</p>
        </section>

        <section id="related-work" class="section">
            <h2>Related Work</h2>
            <p>[Content for Related Work goes here...]</p>
        </section>

        <section id="technical-approach" class="section">
            <h2>Technical Approach</h2>
            <p>Overview of the technical approach.</p>
            <ul>
                <li><a href="#hardware-profiler">Hardware Profiler</a></li>
                <li><a href="#scenarios">Scenarios</a></li>
                <li><a href="#models">Models</a></li>
            </ul>

            <h3 id="hardware-profiler">Hardware Profiler</h3>
            <p>The Hardware Profiler is a core component of FMBench that monitors system resources and energy
                consumption in real-time during benchmark execution. It provides granular insights into how models
                utilize the underlying hardware.</p>

            <h4>Architectural Design & Workflow</h4>
            <p>The profiling system uses a modular architecture managed by a <code>ProfilerManager</code> class. The
                workflow consists of four stages:</p>
            <ol>
                <li><strong>Initialization</strong>: The system automatically detects the underlying hardware platform
                    (Linux, macOS, Windows, Jetson, Raspberry Pi) and instantiates the appropriate profiler classes.
                </li>
                <li><strong>Threaded Monitoring</strong>: Each profiler runs in a dedicated background thread to ensure
                    minimal impact on the benchmarking process.</li>
                <li><strong>Sampling Loop</strong>: The profilers wake up at a configured interval (default: 1.0s),
                    collect metrics from system sensors, write raw data to CSV files, and update in-memory
                    statistics.</li>
                <li><strong>Aggregation</strong>: Upon completion, the manager stops the threads, flushes data to disk,
                    and aggregates statistics (min, max, average, totals) for the final report.</li>
            </ol>

            <h4>Outputs</h4>
            <p>For every benchmark run, the profiler generates:</p>
            <ul>
                <li><strong>CSV Time-Series Data</strong>: Detailed, timestamped logs of all metrics (e.g.,
                    <code>cpu_profiler.csv</code>, <code>mac_profiler.csv</code>).
                </li>
                <li><strong>Aggregated Metrics</strong>: Summary statistics included in the final
                    <code>summary.json</code> (e.g., <code>total_energy_joules</code>,
                    <code>average_gpu_utilization</code>).
                </li>
            </ul>

            <h4>Available Profilers</h4>
            <p>FMBench includes specialized profilers for different hardware architectures:</p>

            <div class="profiler-card">
                <h5>CPU Profiler (Universal)</h5>
                <p><strong>Function</strong>: Monitors CPU and system memory usage on all platforms (Windows, Linux,
                    macOS) using <code>psutil</code>.</p>
                <p><strong>Metrics</strong>: CPU Utilization %, System Memory (Used/%), CPU Temperature.</p>
                <p><strong>Power Monitoring</strong>: On Linux, it attempts to read power sensors via Intel RAPL
                    (Running Average Power Limit) or AMD Energy drivers if available.</p>
            </div>

            <div class="profiler-card">
                <h5>NVIDIA GPU Profiler</h5>
                <p><strong>Function</strong>: Targeted at NVIDIA GPUs (Data Center & Consumer) using the NVML library
                    (via <code>pynvml</code>).</p>
                <p><strong>Metrics</strong>: GPU Utilization %, Memory Usage, Power Draw (Watts), Temperature, Total
                    Energy (Joules).</p>
                <p><strong>Features</strong>: Supports multi-GPU setups by spawning a separate profiler instance for
                    each detected device.</p>
            </div>

            <div class="profiler-card">
                <h5>Mac Profiler (Apple Silicon)</h5>
                <p><strong>Function</strong>: leverages the native <code>powermetrics</code> utility on macOS to capture
                    high-fidelity energy data for M1/M2/M3 chips.</p>
                <p><strong>Metrics</strong>: CPU Power, GPU Power, Apple Neural Engine (ANE) Power, Combined Package
                    Power, GPU Frequency & Utilization.</p>
                <p><strong>Features</strong>: Calculates accurate energy consumption by integrating power measures over
                    time.</p>
            </div>

            <div class="profiler-card">
                <h5>Jetson Profiler</h5>
                <p><strong>Function</strong>: Designed for NVIDIA Jetson devices (Orin, Xavier, Nano) using the
                    <code>jetson-stats</code> (jtop) library.
                </p>
                <p><strong>Metrics</strong>: System Power (POM_5V_IN/VDD_GPU_SOC), GPU/CPU Frequencies, Thermal data,
                    and hardware-specific rail power.</p>
            </div>

            <div class="profiler-card">
                <h5>Raspberry Pi Profiler</h5>
                <p><strong>Function</strong>: Optimized for Raspberry Pi devices.</p>
                <p><strong>Metrics</strong>: CPU/RAM usage and Core Temperature.</p>
                <p><strong>Power Monitoring</strong>: On Raspberry Pi 5, it connects to the PMIC to read real-time
                    voltage and current for accurate power measurement.</p>
            </div>

            <h3 id="scenarios">Scenarios</h3>
            <p>[Details about Scenarios...]</p>
            <p>For a comprehensive list of datasets used across all scenarios, see the <a
                    href="supplementary.html#datasets-used">Datasets Used</a> section in the Supplementary Materials.
            </p>

            <h3 id="models">Models</h3>
            <p>Models are the core entities being benchmarked. The framework uses a flexible, plugin-based architecture
                to support a wide variety of foundation models, ranging from Large Language Models (LLMs) to
                Vision-Language Models (VLMs) and Time-Series Forecasting models.</p>
            <p>For a detailed list of models, see the <a href="supplementary.html#models-used">Models Used</a> section
                in the Supplementary Materials.</p>

            <h4>Architectural Design</h4>
            <p>The model loading system abstracts the complexities of different libraries (Hugging Face Transformers,
                momentfm, chronos, statsmodels) into a unified interface. The core components are:</p>
            <ul>
                <li><strong>BaseModelLoader</strong> (<code>base.py</code>): The abstract base class that defines the
                    contract for all model loaders. It enforces standard methods like <code>load_model</code>,
                    <code>predict</code>, <code>unload_model</code>, and <code>compute_perplexity</code>.
                </li>
                <li><strong>ModelFactory</strong> (<code>model_factory.py</code>): A factory pattern that dynamically
                    simplifies instantiation. It reads the <code>model_category</code> from the configuration (e.g.,
                    <code>LLM</code>, <code>VLM</code>, <code>TIME_SERIES</code>) and returns the appropriate loader
                    class.
                </li>
                <li><strong>Device Utils</strong> (<code>device_utils.py</code>): A shared utility module that handles
                    complex device logic, including automatic MPS (Apple Silicon) compatibility checks, CUDA
                    availability, and int4/int8 quantization configuration.</li>
            </ul>

            <h4>Supported Model Types</h4>

            <div class="model-card">
                <h5>Large Language Models (LLMs)</h5>
                <p><strong>Loader</strong>: <code>HuggingFaceLLMLoader</code></p>
                <p><strong>Description</strong>: Supports any causal language model available on the Hugging Face Hub
                    (e.g., Llama 2/3, Qwen, Mistral, TinyLlama).</p>
                <p><strong>Key Features</strong>:</p>
                <ul>
                    <li>Automatic 4-bit and 8-bit quantization via <code>bitsandbytes</code>.</li>
                    <li>FlashAttention-2 support for optimized inference.</li>
                    <li>Time-To-First-Token (TTFT) measurement using a custom <code>TTFTStreamer</code>.</li>
                </ul>
            </div>

            <div class="model-card">
                <h5>Vision-Language Models (VLMs)</h5>
                <p><strong>Loader</strong>: <code>HuggingFaceVLMLoader</code></p>
                <p><strong>Description</strong>: Models that can process both text and images (e.g., LLaVA, SmolVLM,
                    Qwen-VL).</p>
                <p><strong>Key Features</strong>:</p>
                <ul>
                    <li>Handles complex multimodal tokenization and image preprocessing.</li>
                    <li>Supports multiple input formats (Chat templates, pure text prompts, separate image inputs).</li>
                    <li>Automatic resizing of images to match model encoder requirements (e.g., 336x336 for LLaVA).</li>
                </ul>
            </div>

            <div class="model-card">
                <h5>Time-Series Models</h5>
                <p><strong>Loader</strong>: <code>HuggingFaceTimeSeriesLoader</code></p>
                <p><strong>Description</strong>: A diverse set of forecasting models including Chronos, MOMENT,
                    PatchTST, and classic ARIMA.</p>
                <p><strong>Key Features</strong>:</p>
                <ul>
                    <li><strong>Chronos</strong>: Uses a tokenizer-based approach to treat time series as language.</li>
                    <li><strong>MOMENT</strong>: A foundation model for time series that uses a multi-patch
                        architecture.</li>
                    <li><strong>ARIMA</strong>: Integrated via <code>statsmodels</code> for distinct statistical
                        benchmarking baselines.</li>
                </ul>
            </div>

            <h4>Loading Workflow</h4>
            <p>The framework implements a robust "safe-loading" mechanism to prevent Out-Of-Memory (OOM) errors,
                particularly on edge devices:</p>
            <ol>
                <li><strong>Configuration Parsing</strong>: The system reads the YAML config to determine the model ID
                    and requested parameters (quantization, max tokens, etc.).</li>
                <li><strong>Device Selection</strong>: It checks for available accelerators (CUDA, MPS). For Apple
                    Silicon, it performs a "pre-flight" check to estimate if the model fits within the 1GB tensor limit
                    of the MPS backend.</li>
                <li><strong>Instantiation</strong>: The model is loaded. If 4-bit quantization is requested, the
                    <code>BitsAndBytesConfig</code> is injected.
                </li>
                <li><strong>Placement</strong>: If not already placed by the loader (e.g. via
                    <code>device_map="auto"</code>), the model is explicitly moved to the target device.
                </li>
            </ol>
        </section>

        <section id="evaluation" class="section">
            <h2>Evaluation and Results</h2>
            <p>Overview of evaluation and results.</p>
            <p>For detailed data and raw results, please see the <a href="data_appendix.html">Data Appendix</a>.</p>
        </section>

        <section id="discussions" class="section">
            <h2>Discussions and Conclusions</h2>
            <p>[Content for Discussions and Conclusions goes here...]</p>
        </section>

        <section id="references" class="section">
            <h2>References</h2>
            <p>For a complete list of references including datasets and libraries used in this project, please see the
                <a href="references.html">References</a> page.
            </p>
        </section>

        <footer>
            <p>&copy; 2025 FMBench Project</p>
        </footer>
    </div>
</body>

</html>