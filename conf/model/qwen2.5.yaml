model_id: Qwen/Qwen2.5-1.5B-Instruct
model_category: LLM
max_tokens: 128
use_flash_attention_2: false
# quantization: 4